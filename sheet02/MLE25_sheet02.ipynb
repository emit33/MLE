{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b6a1bb",
   "metadata": {},
   "source": [
    "# Machine Learning Essentials SS25 - Exercise Sheet 2\n",
    "\n",
    "## Instructions\n",
    "- `TODO`'s indicate where you need to complete the implementations.\n",
    "- You may use external resources, but <b>write your own solutions</b>.\n",
    "- Provide concise, but comprehensible comments to explain what your code does.\n",
    "- Code that's unnecessarily extensive and/or not well commented will not be scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.stats import multivariate_normal\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8a873",
   "metadata": {},
   "source": [
    "## Exercise 2 - Implementing LDA\n",
    "\n",
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load digits dataset, visualize one example image of digit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403dfbf2",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e98478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Filter the dataset to keep only digits 3 and 9, split into training and test set (train/test = 3/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c46b2c",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514eba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_2d(x):\n",
    "    \"\"\"\n",
    "    This function takes the 64x1 feature vectors and returns a 2D representation of the data.\n",
    "    \"\"\"\n",
    "    # TODO: Design a 2D embedding of the data\n",
    "    return features_2d\n",
    "\n",
    "# TODO: Create an embedded dataset, provide a brief justification for your choice of embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4ae08",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95601e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_rep(x):\n",
    "    \"\"\"\n",
    "    This function takes the 64x1 feature vectors and returns a 2D representation of the data. It uses PCA to reduce the dimensionality of the data to 2. PCA is a widely used algorithm for dimensionality reduction. Intuitively, PCA finds the directions in which the data varies the most and projects the data onto these directions.\n",
    "    \"\"\"\n",
    "    # Standardize the data\n",
    "    pca = PCA(n_components=2)\n",
    "    return pca.fit_transform(x)\n",
    "\n",
    "# TODO: Create a PCA-embedded dataset. Visualize & compare the embeddings. Briefly discuss the differences in separation achieved by the embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ebd097",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4beae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lda(training_features, training_labels):\n",
    "    \"\"\"\n",
    "    Compute LDA parameters.\n",
    "    \"\"\"\n",
    "    # TODO: Implement LDA\n",
    "\n",
    "    return mu, covmat, p\n",
    "\n",
    "# TODO: Fit seperate LDA models using your hand-crafted embedding, the PCA embedding, and the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d44f4",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc2c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lda(mu, covmat, p, test_features):\n",
    "    \"\"\"\n",
    "    Predict labels using the LDA decision rule.\n",
    "    \"\"\"\n",
    "    # TODO: Implement the LDA decision rule\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "# TODO: Perform LDA on the filtered train sets of all 3 embeddings, evaluate on the respective test set. Report training and test error rates for all 3 embeddings. Error rate = 1 - accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245aff55",
   "metadata": {},
   "source": [
    "### Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898031ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For your hand-crafted embedding, visualize the decision boundary of the LDA classifier over a scatterplot of your data. Use a grid of points to visualize the decision boundary. Bonus: Visualize both Gaussian isocontours of the LDA model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87acf2fb",
   "metadata": {},
   "source": [
    "### Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f8c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_lda(X, y, n_splits):\n",
    "    \"\"\"\n",
    "    Perform n-fold cross-validation for LDA using the earlier defined functions fit_lda and predict_lda.\"\n",
    "    \"\"\"\n",
    "    # TODO: Implement cross-validation for LDA.\n",
    "    return avg_error\n",
    "\n",
    "# TODO: Perform 10-fold CV on the original data. Report average test error rate and its standard error. Compare with the test error rate of the LDA model trained on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451590e",
   "metadata": {},
   "source": [
    "# Exercise 3 - Statistical Darts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3511a3",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf24a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(mu_true, Sigma_true, n_samples):\n",
    "    # TODO: Simulate data from a bivariate Gaussian distribution given the mean and covariance.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a6687",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mle(data):\n",
    "    # TODO: Compute the MLE for the mean of a Gaussian distribution.\n",
    "    return mu_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27c9fa",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b333f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior(data, prior, Sigma_true):\n",
    "    # TODO: Compute the parameters of the posterior distribution for the unknown mean mu.\n",
    "    return mu_post, Sigma_post\n",
    "\n",
    "def compute_map(data, prior, Sigma_true):\n",
    "    # TODO: Assign mode of the posterior to mu_map.\n",
    "    return mu_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a5a194",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_inference(mu_true, mu_mle, mu_map, mu_post, Sigma_post, data,\n",
    "                        grid_limits=[-1, 1, -1, 1], n_points=100):\n",
    "    \"\"\"\n",
    "    Visualizes the full posterior distribution as Gaussian isocontours over a 2D grid with dartboard-like background,\n",
    "    alongside the true mean, MLE estimate, MAP estimate and the simulated data points.\n",
    "\n",
    "    Additional parameters:\n",
    "        grid_limits: [xmin, xmax, ymin, ymax] limits for the 2D grid.\n",
    "        n_points: Number of grid points per axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the grid\n",
    "    xmin, xmax, ymin, ymax = grid_limits\n",
    "    x = np.linspace(xmin, xmax, n_points)\n",
    "    y = np.linspace(ymin, ymax, n_points)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    pos = np.dstack((X, Y))\n",
    "\n",
    "    # Get the posterior distribution\n",
    "    rv = multivariate_normal(mu_post, Sigma_post)\n",
    "    # Evaluate the pdf of the posterior @ the grid points\n",
    "    Z = rv.pdf(pos)\n",
    "    \n",
    "    # Compute some contour levels\n",
    "    levels = np.linspace(Z.max()*0.05, Z.max()*0.95, 7)\n",
    "\n",
    "    plt.figure(figsize=(8, 6), facecolor='white')\n",
    "\n",
    "    # Plot a dartboard-like background (concentric circles)\n",
    "    center = [0,0]\n",
    "    radius = 0.8 \n",
    "    for r in [radius, radius*0.8, radius*0.6, radius*0.4, radius*0.2]:\n",
    "        circle = plt.Circle(center, r, fill=False, color='black')\n",
    "        plt.gca().add_artist(circle)\n",
    "    plt.axis('equal')\n",
    "\n",
    "    # Add bullseye\n",
    "    plt.plot(center[0], center[1], 'o', markersize=10, c='red')\n",
    "\n",
    "    # Plot isocontours of  posterior\n",
    "    contour = plt.contour(X, Y, Z, levels=levels, cmap='viridis',linewidths=1)\n",
    "\n",
    "    # Add labels to the isocontours (off by default for visibility)\n",
    "    # plt.clabel(contour, inline=True, fontsize=8, fmt=\"%.1f\")\n",
    "\n",
    "    # Plot observed data points\n",
    "    plt.scatter(data[:, 0], data[:, 1], c='gray', edgecolor='k', alpha=0.6, label='Data')\n",
    "\n",
    "    # Plot true mean (ground truth)\n",
    "    plt.scatter(mu_true[0], mu_true[1], c='black', marker='*', s=200, label='True aiming spot')\n",
    "\n",
    "    # Plot MLE estimate\n",
    "    plt.scatter(mu_mle[0], mu_mle[1], c='green', marker='x', s=100, label='MLE Estimate')\n",
    "\n",
    "    # Plot MAP estimate \n",
    "    plt.scatter(mu_map[0], mu_map[1], c='blue', marker='x', s=100, label='MAP Estimate')\n",
    "\n",
    "    plt.title(\"True Mean, posterior uncertainty, MLE & MAP on the dart board\")\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8baf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth parameters for the dart throws:\n",
    "mu_true = np.array([0, 0.50])\n",
    "Sigma_true = np.array([[0.05, 0.02],\n",
    "                       [0.02, 0.04]])\n",
    "\n",
    "# Prior for mu - standard normal around the bullseye\n",
    "prior = {\n",
    "    \"mu0\": np.array([0, 0]),\n",
    "    \"Sigma0\": np.eye(2)\n",
    "}\n",
    "\n",
    "# TODO: Simulate data, compute MLE, MAP and posterior\n",
    "\n",
    "# Visualize the inference\n",
    "visualize_inference(mu_true, mu_mle, mu_map, mu_post, Sigma_post, data)\n",
    "print(f\"MLE estimate for N={n_samples}:\", mu_mle)\n",
    "print(f\"MAP estimate for N={n_samples}:\", mu_map)\n",
    "print(f\"Posterior covariance for N={n_samples}:\\n\", Sigma_post)\n",
    "\n",
    "# TODO: Assess results (see exercise sheet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
